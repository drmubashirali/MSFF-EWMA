#XGBoost with sensitivity and specificity
import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.utils import shuffle

xgb_clf = XGBClassifier(
    learning_rate=0.01,
    max_depth=3,
    n_estimators=100,
    subsample=0.8,
    random_state=42  
)

fold_files = [f'./dataset/preprocessed_svg1/fold{i}final.csv' for i in range(1, 7)]

def evaluate_model(X_train, y_train, X_test, y_test):
    # Shuffle the training and testing data
    X_train, y_train = shuffle(X_train, y_train, random_state=32)
    X_test, y_test = shuffle(X_test, y_test, random_state=32)
    X_test = X_test[X_train.columns]
    
    xgb_clf.fit(X_train, y_train)
    xgb_y_pred = xgb_clf.predict(X_test)
    xgb_y_prob = xgb_clf.predict_proba(X_test)[:, 1]
    accuracy = accuracy_score(y_test, xgb_y_pred)
    recall = recall_score(y_test, xgb_y_pred)
    f1 = f1_score(y_test, xgb_y_pred)
    tn, fp, fn, tp = confusion_matrix(y_test, xgb_y_pred).ravel()
    
    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0
    
    xgb_metrics = {
        'Accuracy': accuracy,
        'Recall (Sensitivity)': recall,
        'Specificity': specificity,
        'F1 Score': f1,
        'AUC': roc_auc_score(y_test, xgb_y_prob)
    }

    return xgb_metrics

# Perform 6-fold cross-validation
all_fold_metrics = []

for i in range(6):
    test_file = fold_files[i]
    train_files = [file for j, file in enumerate(fold_files) if j != i]

    test_df = pd.read_csv(test_file)
    X_test = test_df.drop(columns=['ID', 'Label'])
    y_test = test_df['Label']

    train_dfs = [pd.read_csv(file) for file in train_files]
    train_df = pd.concat(train_dfs, ignore_index=True)
    X_train = train_df.drop(columns=['ID', 'Label'])
    y_train = train_df['Label']

    print(f"Results for fold {i + 1}:")
    fold_metrics = evaluate_model(X_train, y_train, X_test, y_test)
    all_fold_metrics.append(fold_metrics)
    for metric, value in fold_metrics.items():
        print(f"{metric}: {value:.4f}")
    print("\n")

# Calculate and print mean and standard deviation of results of all folds
mean_metrics = {}
std_metrics = {}
for metric in all_fold_metrics[0].keys():
    metric_values = [fold_metrics[metric] for fold_metrics in all_fold_metrics]
    mean_metrics[metric] = np.mean(metric_values)
    std_metrics[metric] = np.std(metric_values)

print("Average results over all folds:")
for metric in mean_metrics.keys():
    print(f"{metric}: {mean_metrics[metric]:.4f} Â± {std_metrics[metric]:.4f}")
