#XGBoost with sensitivity and specificity
import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.utils import shuffle

xgb_clf = XGBClassifier(
    learning_rate=0.01,
    max_depth=3,
    n_estimators=100,
    subsample=0.8,
    random_state=42  
)

fold_files = [f'./dataset/preprocessed_svg1/fold{i}final.csv' for i in range(1, 7)]

def evaluate_model(X_train, y_train, X_test, y_test):
    # Shuffle the training and testing data
    X_train, y_train = shuffle(X_train, y_train, random_state=32)
    X_test, y_test = shuffle(X_test, y_test, random_state=32)
    X_test = X_test[X_train.columns]
    
    xgb_clf.fit(X_train, y_train)
    xgb_y_pred = xgb_clf.predict(X_test)
    xgb_y_prob = xgb_clf.predict_proba(X_test)[:, 1]
    accuracy = accuracy_score(y_test, xgb_y_pred)
    recall = recall_score(y_test, xgb_y_pred)
    f1 = f1_score(y_test, xgb_y_pred)
    tn, fp, fn, tp = confusion_matrix(y_test, xgb_y_pred).ravel()
    
    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0
    
    xgb_metrics = {
        'Accuracy': accuracy,
        'Recall (Sensitivity)': recall,
        'Specificity': specificity,
        'F1 Score': f1,
        'AUC': roc_auc_score(y_test, xgb_y_prob)
    }

    return xgb_metrics

# Perform 6-fold cross-validation
all_fold_metrics = []

for i in range(6):
    test_file = fold_files[i]
    train_files = [file for j, file in enumerate(fold_files) if j != i]

    test_df = pd.read_csv(test_file)
    X_test = test_df.drop(columns=['ID', 'Label'])
    y_test = test_df['Label']

    train_dfs = [pd.read_csv(file) for file in train_files]
    train_df = pd.concat(train_dfs, ignore_index=True)
    X_train = train_df.drop(columns=['ID', 'Label'])
    y_train = train_df['Label']

    print(f"Results for fold {i + 1}:")
    fold_metrics = evaluate_model(X_train, y_train, X_test, y_test)
    all_fold_metrics.append(fold_metrics)
    for metric, value in fold_metrics.items():
        print(f"{metric}: {value:.4f}")
    print("\n")

# Calculate and print mean and standard deviation of results of all folds
mean_metrics = {}
std_metrics = {}
for metric in all_fold_metrics[0].keys():
    metric_values = [fold_metrics[metric] for fold_metrics in all_fold_metrics]
    mean_metrics[metric] = np.mean(metric_values)
    std_metrics[metric] = np.std(metric_values)

print("Average results over all folds:")
for metric in mean_metrics.keys():
    print(f"{metric}: {mean_metrics[metric]:.4f} Â± {std_metrics[metric]:.4f}")


#XAI Part#
import shap
from sklearn.metrics import accuracy_score
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('new_abc.csv')
X = data.drop(['ID', 'Label'], axis=1)
y = data['Label']
data_shuffled = data.sample(frac=1, random_state=42).reset_index(drop=True)
X_shuffled = data_shuffled.drop(['ID', 'Label'], axis=1)
y_shuffled = data_shuffled['Label']
X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.3, random_state=42)
clf = XGBClassifier(
    learning_rate=0.01,
    max_depth=3,
    n_estimators=100,
    subsample=0.8,
    random_state=42  
)
clf.fit(X_train, y_train)

explainer = shap.Explainer(clf, X_train)
shap_values = explainer(X_test)
fig, ax = plt.subplots(figsize=(10, 6))
shap.plots.beeswarm(shap_values, show=False)  # Prevent automatic display
plt.savefig('beeswarm_plot.png', bbox_inches='tight', dpi=300)
plt.show()

shap_means = np.abs(shap_values).mean(axis=0)
top_n = 12
top_indices = np.argsort(shap_means)[-top_n:]
other_shap_values = shap_values[:, np.argsort(shap_means)[:-top_n]].sum(axis=1)
combined_shap_values = np.hstack([shap_values[:, top_indices], other_shap_values.reshape(-1, 1)])
top_feature_names = X_test.columns[top_indices].tolist()
feature_names = top_feature_names + [f'Sum of {len(X_test.columns) - top_n} other features']
shap_values_df = pd.DataFrame(combined_shap_values, columns=feature_names)
fig, ax = plt.subplots(figsize=(10, 6))
shap.summary_plot(shap_values_df.values, feature_names=feature_names, plot_type="bar", show=False)  # Prevent automatic display
plt.savefig('summary_plot.png', bbox_inches='tight', dpi=600)
plt.show()


shap.initjs()
shap_values_sample = shap_values[:10]
expected_value = explainer.expected_value
shap.force_plot(expected_value, shap_values_sample, X_test.iloc[:10,:])
shap.decision_plot(expected_value, shap_values, X_test, ignore_warnings=True)
plt.savefig('decision_plot.png', bbox_inches='tight', dpi=300)


shap_exp = shap.Explanation(values=shap_values[0],
                            base_values=explainer.expected_value,
                            data=X_test.iloc[0],
                            feature_names=X_test.columns)
fig, ax = plt.subplots(figsize=(3.33, 2.2))
shap.waterfall_plot(shap_exp, show=False)
plt.rcParams['font.family'] = 'Times New Roman'
plt.rcParams['font.size'] = 10
plt.savefig('waterfall_plot.png', bbox_inches='tight', dpi=600)
plt.show()
plt.close()
